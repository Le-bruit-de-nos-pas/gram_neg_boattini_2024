{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import fisher_exact, mannwhitneyu\n",
    "\n",
    "import shap\n",
    "import xgboost\n",
    "import inspect\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/neg_bacilli_turin_2024.txt', delimiter='\\t')\n",
    "print(df)\n",
    "for name in df.columns:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total missing # :\", df.isna().sum().sum())\n",
    "print(\"Total missing % :\", 100* df.isna().sum().sum() / (df.shape[0]*df.shape[1]) )\n",
    "df.fillna(0, inplace=True)\n",
    "print(\"Total missing # :\", df.isna().sum().sum())\n",
    "print(\"Total missing % :\", 100* df.isna().sum().sum() / (df.shape[0]*df.shape[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_se_proportion(p, n):\n",
    "    return np.sqrt((p * (1 - p)) / n).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(df):\n",
    "    \"\"\" Generate summary table.\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame for which to generate the summary table.\n",
    "    Returns:\n",
    "    DataFrame: The summary table.\"\"\"\n",
    "\n",
    "    # Generate summary statistics for ALL columns\n",
    "    summary_table = df.describe()\n",
    "    # Transpose the summary table\n",
    "    summary_table = summary_table.T\n",
    "    # Round all values to two decimal points\n",
    "    summary_table = summary_table.round(2)\n",
    "    # Create 'Mean ± Std' column\n",
    "    summary_table['Mean ± Std'] = summary_table.apply(lambda row: f\"{row['mean']} ± {row['std']}\", axis=1)\n",
    "    # Create 'Median [IQR]' column\n",
    "    summary_table['Median [IQR]'] = summary_table.apply(lambda row: f\"{row['50%']} [{row['25%']}-{row['75%']}]\", axis=1)\n",
    "    # Create 'Proportion ± SE' column\n",
    "    summary_table['Proportion ± SE'] = summary_table.apply(lambda row: f\"{row['mean']} ± {calculate_se_proportion(row['mean'], row['count'])}\", axis=1)\n",
    "    # Create 'SE_Error_Flag' column\n",
    "    summary_table['SE_Error_Flag'] = summary_table['Proportion ± SE'].apply(lambda row: 1 if 'nan' in str(row) else 0)\n",
    "    # Reset the index\n",
    "    summary_table.reset_index(inplace=True)\n",
    "    # Create 'Row_Number' column\n",
    "    summary_table['Row_Number'] = summary_table.index + 1\n",
    "    # Drop unnecessary columns\n",
    "    summary_table.drop(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], axis=1, inplace=True)\n",
    "\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = create_summary_table(df)\n",
    "summary_table.to_csv('../data/summary_table.csv')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats + Fisher's Exat Test | Wilcoxon/Mann-Whitney Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive >2 cultures  || +50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cult_pos = df[df['Positive_2culture_50perc'] == 1] # 43 out of 63\n",
    "summary_table = create_summary_table(df_cult_pos)\n",
    "summary_table.to_csv('../data/summary_table_cult_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cult_neg = df[df['Positive_2culture_50perc'] == 0] # 20 out of 63\n",
    "summary_table = create_summary_table(df_cult_neg)\n",
    "summary_table.to_csv('../data/summary_table_cult_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['Positive_2culture_50perc', 'pat_id']\n",
    "binary_results = []\n",
    "numeric_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in exclude_cols:\n",
    "        if df[col].nunique() <= 2:\n",
    "            filtered_col = df[col].dropna().astype(int)\n",
    "            if filtered_col.nunique() == 2:\n",
    "                contingency_table = pd.crosstab(df['Positive_2culture_50perc'], filtered_col)\n",
    "                odds_ratio , p_value = fisher_exact(contingency_table)\n",
    "                binary_results.append((col, odds_ratio, p_value))\n",
    "            else:\n",
    "                print(f\"Warning: Colunm '{col}' does not exactly 2 unique values. Dropping it...\" )\n",
    "        else:\n",
    "            group_1 = df[df['Positive_2culture_50perc'] == 1][col]\n",
    "            group_2 = df[df['Positive_2culture_50perc'] == 0][col]\n",
    "            _ , p_value = mannwhitneyu(group_1, group_2, alternative='two-sided')\n",
    "            numeric_results.append((col, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numeric Variables (Wilcoxon/Mann-Whitney Test): \")\n",
    "for result in numeric_results:\n",
    "    print(f\"{result[0]} , p-value: {result[1]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Binary Variables (Fisher's Exact Test): \")\n",
    "for result in binary_results:\n",
    "    print(f\"{result[0]} - Odds Ratio: {result[1]}, p-value: {result[2]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Hospital Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats + Fisher's Exat Test | Wilcoxon/Mann-Whitney Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_mort_pos = df[df['Mortality_hospital'] == 1] # 10 out of 63\n",
    "summary_table = create_summary_table(df_hosp_mort_pos)\n",
    "summary_table.to_csv('../data/summary_table_hosp_mort_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_mort_neg = df[df['Mortality_hospital'] == 0] # 53 out of 63\n",
    "summary_table = create_summary_table(df_hosp_mort_neg)\n",
    "summary_table.to_csv('../data/summary_table_hosp_mort_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['Mortality_hospital', 'pat_id', 'Amoxicillin_clavulanate_including', 'Metronidazole_including', 'Mortality_30_days', 'Mortality_14_days']\n",
    "binary_results = []\n",
    "numeric_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in exclude_cols:\n",
    "        if df[col].nunique() <= 2:\n",
    "            filtered_col = df[col].dropna().astype(int)\n",
    "            if filtered_col.nunique() == 2:\n",
    "                contingency_table = pd.crosstab(df['Mortality_hospital'], filtered_col)\n",
    "                odds_ratio , p_value = fisher_exact(contingency_table)\n",
    "                binary_results.append((col, odds_ratio, p_value))\n",
    "            else:\n",
    "                print(f\"Warning: Colunm '{col}' does not exactly 2 unique values. Dropping it...\" )\n",
    "        else:\n",
    "            group_1 = df[df['Mortality_hospital'] == 1][col]\n",
    "            group_2 = df[df['Mortality_hospital'] == 0][col]\n",
    "            _ , p_value = mannwhitneyu(group_1, group_2, alternative='two-sided')\n",
    "            numeric_results.append((col, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numeric Variables (Wilcoxon/Mann-Whitney Test): \")\n",
    "for result in numeric_results:\n",
    "    print(f\"{result[0]} , p-value: {result[1]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Binary Variables (Fisher's Exact Test): \")\n",
    "for result in binary_results:\n",
    "    print(f\"{result[0]} - Odds Ratio: {result[1]}, p-value: {result[2]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/neg_bacilli_turin_2024.txt', delimiter='\\t')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['pat_id', 'Amoxicillin_clavulanate_including', 'Metronidazole_including', 'Mortality_30_days', 'Mortality_14_days']\n",
    "columns_to_drop = ['pat_id', 'Amoxicillin_clavulanate_including', 'Metronidazole_including', 'Mortality_30_days', 'Mortality_14_days', 'LOS_days']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Mortality_hospital']\n",
    "X = df.drop(columns=['Mortality_hospital'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X100 = shap.utils.sample(X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier(nestimators=100, max_depth=2, objective = \"binary:logistic\").fit(X, y)\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.display_data = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(shap_values[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[41])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[36])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[35])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[60])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[27])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values.abs.max(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values.abs, color=\"shap_red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values, max_display=10, plot_width=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/neg_bacilli_turin_2024.txt', delimiter='\\t')\n",
    "df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['pat_id', 'Amoxicillin_clavulanate_including', 'Metronidazole_including', 'Mortality_14_days', 'Mortality_30_days', 'LOS_days']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_features = numerical_features.drop(columns=['Mortality_hospital'])\n",
    "\n",
    "binary_numerical_features = [col for col in numerical_features.columns if numerical_features[col].nunique() == 2]\n",
    "\n",
    "non_binary_numerical_features = numerical_features.drop(columns=binary_numerical_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical_features = scaler.fit_transform(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_features.columns] = scaled_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.drop(columns=['Mortality_hospital']).select_dtypes(include=['float64', 'int64'])\n",
    "numerical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99) \n",
    "pca.fit(numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = pca.transform(numerical_features)\n",
    "principal_components_df = pd.DataFrame(data=principal_components, \n",
    "                                       columns=[f'PC{i}' for i in range(1, pca.n_components_ + 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca.components_\n",
    "loadings_df = pd.DataFrame(loadings, columns=numerical_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, component in enumerate(loadings_df.iterrows(), start=1):\n",
    "    print(f\"Principal Component {i} Loadings:\")\n",
    "    print(component)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "sns.heatmap(loadings_df.T, cmap='coolwarm', annot=True, fmt=\".1f\", cbar=False)\n",
    "plt.title('Principal Component Loadings')\n",
    "plt.xlabel(None)  \n",
    "plt.ylabel(None)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='-')\n",
    "plt.title('Cumulative Explained Variance Ratio')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.xticks(range(1, len(cumulative_variance_ratio) + 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Mortality_hospital']\n",
    "\n",
    "correlation_with_y = principal_components_df.apply(lambda col: col.corr(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_with_y_sorted = correlation_with_y.abs().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation with Output Variable (Absolute Values):\")\n",
    "print(correlation_with_y_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_with_y = pd.concat([principal_components_df, y], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loadings_by_y = pca_with_y.groupby('Mortality_hospital').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Loadings by Output Variable Group:\")\n",
    "print(mean_loadings_by_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loadings_by_y.index = mean_loadings_by_y.index.map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 1))\n",
    "sns.heatmap(mean_loadings_by_y, cmap='RdGy', annot=True, fmt=\".1f\", cbar=True)\n",
    "plt.title('Mean Loadings by In-hospital Mortality Status')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('In-hospital Mortality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_by_pc = {}\n",
    "\n",
    "for pc in loadings_df.index:\n",
    "    top_features_by_pc[pc] = loadings_df.loc[pc].abs().nlargest(5).index.tolist()\n",
    "\n",
    "for pc, features in top_features_by_pc.items():\n",
    "    print(f\"Principal Component {pc}: {features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
